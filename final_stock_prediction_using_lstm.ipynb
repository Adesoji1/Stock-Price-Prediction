{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first install the numerapi library, which provides an interface to the Numerai API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numerapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numerapi\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will authenticate our API key."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will download the current tournament data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download current round data\n",
    "data_path = \"numerai_dataset.zip\"\n",
    "napi.download_current_dataset(dest_path=data_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download current round data\n",
    "data_path = \"numerai_dataset.zip\"\n",
    "napi.download_current_dataset(dest_path=data_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in a compressed format, so we will extract it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(data_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(r'C:\\Users\\Sortolng\\Downloads\\traindata.csv')\n",
    "test_df =  pd.read_csv(r'C:\\Users\\Sortolng\\Downloads\\testdata.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data contains 501,808 rows and 314 columns, where the first column is the id, the second column is the era, and the last column is the target variable, which we will try to predict.\n",
    "\n",
    "We will print the first few rows of the training data to get an idea of the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                id   era data_type  feature_intelligence1  \\\n",
      "0           0  n000315175b67977  era1     train                   0.00   \n",
      "1           1  n0014af834a96cdd  era1     train                   0.00   \n",
      "2           2  n001c93979ac41d4  era1     train                   0.25   \n",
      "3           3  n0034e4143f22a13  era1     train                   1.00   \n",
      "4           4  n00679d1a636062f  era1     train                   0.25   \n",
      "\n",
      "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
      "0                   0.50                   0.25                   0.00   \n",
      "1                   0.00                   0.00                   0.25   \n",
      "2                   0.50                   0.25                   0.25   \n",
      "3                   0.00                   0.00                   0.50   \n",
      "4                   0.25                   0.25                   0.25   \n",
      "\n",
      "   feature_intelligence5  feature_intelligence6  ...  feature_wisdom38  \\\n",
      "0                    0.5                   0.25  ...              1.00   \n",
      "1                    0.5                   0.00  ...              1.00   \n",
      "2                    1.0                   0.75  ...              0.25   \n",
      "3                    0.5                   0.25  ...              1.00   \n",
      "4                    0.0                   0.25  ...              0.75   \n",
      "\n",
      "   feature_wisdom39  feature_wisdom40  feature_wisdom41  feature_wisdom42  \\\n",
      "0              1.00              0.75              0.50              0.75   \n",
      "1              1.00              0.00              0.00              0.75   \n",
      "2              0.50              0.00              0.00              0.50   \n",
      "3              1.00              0.75              0.75              1.00   \n",
      "4              0.75              0.25              0.50              0.75   \n",
      "\n",
      "   feature_wisdom43  feature_wisdom44  feature_wisdom45  feature_wisdom46  \\\n",
      "0              0.50              1.00              0.50              0.75   \n",
      "1              0.25              0.00              0.25              1.00   \n",
      "2              1.00              0.00              0.25              0.75   \n",
      "3              1.00              0.75              1.00              1.00   \n",
      "4              0.00              0.50              0.25              0.75   \n",
      "\n",
      "   target  \n",
      "0    0.50  \n",
      "1    0.25  \n",
      "2    0.25  \n",
      "3    0.25  \n",
      "4    0.75  \n",
      "\n",
      "[5 rows x 315 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print first few rows\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a function to split the data into features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find only the feature columns\n",
    "feature_cols = train_df.columns[train_df.columns.str.startswith('feature')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select those columns out of the training dataset\n",
    "training_features = train_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.049711504080342465\n"
     ]
    }
   ],
   "source": [
    "# create a model and fit the training data (~30 sec to run) using Linear regression\n",
    "import sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model0 = sklearn.linear_model.LinearRegression()\n",
    "model0.fit(training_features, train_df.target)\n",
    "# Predict on training data\n",
    "y_pred_train = model0.predict(training_features)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse_train = mean_squared_error(train_df.target, y_pred_train)\n",
    "print(\"Training MSE:\", mse_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate your first predictions from the Linear regression model\n",
    "Now that we have a trained model, we can use it to make predictions on the tournament data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the feature columns from the tournament data\n",
    "live_features = test_df[feature_cols]\n",
    "     \n",
    "\n",
    "# predict the target on the live features\n",
    "predictions = model0.predict(live_features)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0003aa52cab36c2</td>\n",
       "      <td>0.481608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n000920ed083903f</td>\n",
       "      <td>0.492837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n0038e640522c4a6</td>\n",
       "      <td>0.530817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n004ac94a87dc54b</td>\n",
       "      <td>0.497083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n0052fe97ea0c05f</td>\n",
       "      <td>0.503089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n00a5ccf3b6b2870</td>\n",
       "      <td>0.502672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n00bf78d0bbbc1b6</td>\n",
       "      <td>0.511966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n00c6fd95ff0c83e</td>\n",
       "      <td>0.497699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n00cd56868258aec</td>\n",
       "      <td>0.492206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n00e7d6fb71ef69f</td>\n",
       "      <td>0.476394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  n0003aa52cab36c2    0.481608\n",
       "1  n000920ed083903f    0.492837\n",
       "2  n0038e640522c4a6    0.530817\n",
       "3  n004ac94a87dc54b    0.497083\n",
       "4  n0052fe97ea0c05f    0.503089\n",
       "5  n00a5ccf3b6b2870    0.502672\n",
       "6  n00bf78d0bbbc1b6    0.511966\n",
       "7  n00c6fd95ff0c83e    0.497699\n",
       "8  n00cd56868258aec    0.492206\n",
       "9  n00e7d6fb71ef69f    0.476394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions must have an `id` column and a `prediction` column\n",
    "predictions_df = test_df[\"id\"].to_frame()\n",
    "predictions_df[\"prediction\"] = predictions\n",
    "predictions_df.head(10)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comapring with Linear regression using another model usinng Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Random forest regression\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(training_features, train_df.target)\n",
    "rf_pred = rf.predict(live_features)\n",
    "\n",
    "# Support vector regression\n",
    "svm = SVR(kernel='rbf')\n",
    "svm.fit(training_features, train_df.target)\n",
    "svm_pred = svm.predict(live_features)\n",
    "\n",
    "# Evaluate the performance of the models\n",
    "print('Random Forest Regression')\n",
    "print('MAE:', mean_absolute_error(train_df.target, rf_pred))\n",
    "print('RMSE:', mean_squared_error(train_df.target, rf_pred, squared=False))\n",
    "print('MSE:', mean_squared_error(train_df.target, rf_pred))\n",
    "print('R^2:', r2_score(train_df.target, rf_pred))\n",
    "print()\n",
    "print('Support Vector Regression')\n",
    "print('MAE:', mean_absolute_error(train_df.target, svm_pred))\n",
    "print('RMSE:', mean_squared_error(train_df.target, svm_pred, squared=False))\n",
    "print('MSE:', mean_squared_error(train_df.target, svm_pred))\n",
    "print('R^2:', r2_score(train_df.target, svm_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#comparing with another model and testing from the train data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `code` above will output the MAE, RMSE, MSE, and R-squared scores for both the random forest regression and SVM models. You can adjust the hyperparameters of the models as needed to improve performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make your first submission for the first model(Linear regression)\n",
    "To enter the tournament, we must submit the predictions back to Numerai. We will use the numerapi library to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your API keys and model_id from https://numer.ai/notebook\n",
    "public_id = \"J4SPYZOFARWFLPXCK2NZE5F4ML2CJQA2\"\n",
    "secret_key = \"IEXQ372PB7TQSK4YGJ7MYNVCOCM33L7QQ3A2FUIMBJ2HMSK4BHUM3BOCISKHMKSA\"\n",
    "model_id = \"ab3f7e70-452f-4a04-b228-0b52efbc09c0\"\n",
    "napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 23:27:57,759 INFO numerapi.base_api: uploading predictions...\n",
      "2023-02-23 23:34:47,868 ERROR numerapi.base_api: You must provide predictions for the current live IDs. Make sure you are using the latest live data.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You must provide predictions for the current live IDs. Make sure you are using the latest live data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Upload your predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m predictions_df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mpredictions.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m submission_id \u001b[39m=\u001b[39m napi\u001b[39m.\u001b[39;49mupload_predictions(\u001b[39m\"\u001b[39;49m\u001b[39mpredictions.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, model_id\u001b[39m=\u001b[39;49mmodel_id)\n",
      "File \u001b[1;32mc:\\Users\\Sortolng\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numerapi\\numerapi.py:614\u001b[0m, in \u001b[0;36mNumerAPI.upload_predictions\u001b[1;34m(self, file_path, tournament, model_id, df)\u001b[0m\n\u001b[0;32m    596\u001b[0m create_query \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[0;32m    597\u001b[0m \u001b[39m    mutation($filename: String!\u001b[39m\n\u001b[0;32m    598\u001b[0m \u001b[39m             $tournament: Int!\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[39m    }\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39m\n\u001b[0;32m    610\u001b[0m arguments \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m: upload_auth[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    611\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mtournament\u001b[39m\u001b[39m'\u001b[39m: tournament,\n\u001b[0;32m    612\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mmodelId\u001b[39m\u001b[39m'\u001b[39m: model_id,\n\u001b[0;32m    613\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mtriggerId\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mTRIGGER_ID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)}\n\u001b[1;32m--> 614\u001b[0m create \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_query(create_query, arguments, authorization\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    615\u001b[0m submission_id \u001b[39m=\u001b[39m create[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcreate_submission\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    616\u001b[0m \u001b[39mreturn\u001b[39;00m submission_id\n",
      "File \u001b[1;32mc:\\Users\\Sortolng\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numerapi\\base_api.py:132\u001b[0m, in \u001b[0;36mApi.raw_query\u001b[1;34m(self, query, variables, authorization, retries, delay, backoff)\u001b[0m\n\u001b[0;32m    130\u001b[0m     err \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_call_error(result[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    131\u001b[0m     \u001b[39m# fail!\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide predictions for the current live IDs. Make sure you are using the latest live data."
     ]
    }
   ],
   "source": [
    "# Upload your predictions\n",
    "predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "submission_id = napi.upload_predictions(\"predictions.csv\", model_id=model_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above error is an error yet to be resolved  though i downloaded the latest data and it is found in this forum. https://forum.numer.ai/t/faced-an-error-while-uploading-predictions/6069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7e7c2d9b6cf9197157429b5ec1a161a658a81c03ed4cc25f0eabd4add521f81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
